{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "\n",
    "prestigeAndAdmit = df.groupby([\"admit\",\"prestige\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>admit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>93</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "admit      0   1\n",
       "prestige        \n",
       "1.0       28  33\n",
       "2.0       95  53\n",
       "3.0       93  28\n",
       "4.0       55  12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcross = pd.crosstab(df.prestige,df.admit)\n",
    "dfcross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">gpa</th>\n",
       "      <th colspan=\"8\" halign=\"left\">gre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th>prestige</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.345714</td>\n",
       "      <td>0.375445</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.1350</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.5775</td>\n",
       "      <td>4.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>582.857143</td>\n",
       "      <td>126.574737</td>\n",
       "      <td>340.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>3.325895</td>\n",
       "      <td>0.376339</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.0700</td>\n",
       "      <td>3.350</td>\n",
       "      <td>3.5850</td>\n",
       "      <td>4.00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>103.323495</td>\n",
       "      <td>380.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>93.0</td>\n",
       "      <td>3.402258</td>\n",
       "      <td>0.379434</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.1400</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.6900</td>\n",
       "      <td>4.00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>562.365591</td>\n",
       "      <td>124.650798</td>\n",
       "      <td>220.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>3.291455</td>\n",
       "      <td>0.369767</td>\n",
       "      <td>2.26</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>3.310</td>\n",
       "      <td>3.4750</td>\n",
       "      <td>4.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>562.909091</td>\n",
       "      <td>116.327646</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>1.0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>3.544242</td>\n",
       "      <td>0.385511</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>3.610</td>\n",
       "      <td>3.8100</td>\n",
       "      <td>4.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>636.363636</td>\n",
       "      <td>110.618098</td>\n",
       "      <td>460.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>3.441698</td>\n",
       "      <td>0.365054</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>3.450</td>\n",
       "      <td>3.7500</td>\n",
       "      <td>4.00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>612.075472</td>\n",
       "      <td>113.635018</td>\n",
       "      <td>300.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.534643</td>\n",
       "      <td>0.399244</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.3425</td>\n",
       "      <td>3.620</td>\n",
       "      <td>3.8625</td>\n",
       "      <td>4.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>616.428571</td>\n",
       "      <td>99.785484</td>\n",
       "      <td>460.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.441667</td>\n",
       "      <td>0.297286</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>3.535</td>\n",
       "      <td>3.6625</td>\n",
       "      <td>3.74</td>\n",
       "      <td>12.0</td>\n",
       "      <td>603.333333</td>\n",
       "      <td>114.680056</td>\n",
       "      <td>400.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gpa                                                         \\\n",
       "               count      mean       std   min     25%    50%     75%   max   \n",
       "admit prestige                                                                \n",
       "0     1.0       28.0  3.345714  0.375445  2.55  3.1350  3.280  3.5775  4.00   \n",
       "      2.0       95.0  3.325895  0.376339  2.42  3.0700  3.350  3.5850  4.00   \n",
       "      3.0       93.0  3.402258  0.379434  2.56  3.1400  3.400  3.6900  4.00   \n",
       "      4.0       55.0  3.291455  0.369767  2.26  3.0500  3.310  3.4750  4.00   \n",
       "1     1.0       33.0  3.544242  0.385511  2.42  3.3700  3.610  3.8100  4.00   \n",
       "      2.0       53.0  3.441698  0.365054  2.62  3.1700  3.450  3.7500  4.00   \n",
       "      3.0       28.0  3.534643  0.399244  2.65  3.3425  3.620  3.8625  4.00   \n",
       "      4.0       12.0  3.441667  0.297286  2.86  3.2200  3.535  3.6625  3.74   \n",
       "\n",
       "                 gre                                                      \\\n",
       "               count        mean         std    min    25%    50%    75%   \n",
       "admit prestige                                                             \n",
       "0     1.0       28.0  582.857143  126.574737  340.0  510.0  580.0  685.0   \n",
       "      2.0       95.0  588.000000  103.323495  380.0  520.0  580.0  660.0   \n",
       "      3.0       93.0  562.365591  124.650798  220.0  500.0  560.0  640.0   \n",
       "      4.0       55.0  562.909091  116.327646  300.0  500.0  560.0  630.0   \n",
       "1     1.0       33.0  636.363636  110.618098  460.0  540.0  620.0  720.0   \n",
       "      2.0       53.0  612.075472  113.635018  300.0  540.0  620.0  680.0   \n",
       "      3.0       28.0  616.428571   99.785484  460.0  535.0  620.0  680.0   \n",
       "      4.0       12.0  603.333333  114.680056  400.0  520.0  610.0  685.0   \n",
       "\n",
       "                       \n",
       "                  max  \n",
       "admit prestige         \n",
       "0     1.0       800.0  \n",
       "      2.0       800.0  \n",
       "      3.0       800.0  \n",
       "      4.0       800.0  \n",
       "1     1.0       800.0  \n",
       "      2.0       800.0  \n",
       "      3.0       800.0  \n",
       "      4.0       780.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the grouped data\n",
    "\n",
    "prestigeAndAdmit.describe().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0             0             0             1             0\n",
       "1             0             0             1             0\n",
       "2             1             0             0             0\n",
       "3             0             0             0             1\n",
       "4             0             0             0             1\n",
       "5             0             1             0             0\n",
       "6             1             0             0             0\n",
       "7             0             1             0             0\n",
       "8             0             0             1             0\n",
       "9             0             1             0             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I'm prepping my data for logistic regression by creating dummy variables of my predictor column.\n",
    "\n",
    "dummy_ranks = pd.get_dummies(df['prestige'],prefix = 'prestige')\n",
    "\n",
    "dummy_ranks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We only need 3 dummy variables 'prestige_2.0', 'prestige_3.0', & 'prestige_4.0' because it helps us avoid collinearity. Also, we can safely assume that any prestige that is not 2-4 can correctly be classified as 'prestige_1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61             0             0             1             0\n",
      "1      1  660.0  3.67             0             0             1             0\n",
      "2      1  800.0  4.00             1             0             0             0\n",
      "3      1  640.0  3.19             0             0             0             1\n",
      "4      0  520.0  2.93             0             0             0             1\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "\n",
    "handCalc = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_1':])\n",
    "print handCalc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige_1.0    0   1\n",
      "admit                \n",
      "0             243  28\n",
      "1              93  33\n"
     ]
    }
   ],
   "source": [
    "#crosstab prestige 1 admission \n",
    "#crosstab basically produces a pivot table\n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "\n",
    "print pd.crosstab(handCalc['admit'], handCalc['prestige_1.0'], rownames= ['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "\n",
    "castType = df.prestige.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17857142857\n"
     ]
    }
   ],
   "source": [
    "# odds formula = (# of times an event occurs / # of time an event does not occur)\n",
    "\n",
    "odds_admission1 = (33./28)\n",
    "print odds_admission1\n",
    "\n",
    "# According to this calculation, the odds of being admitted to grad school after attending a #1 ranked college are ~1.18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382716049383\n"
     ]
    }
   ],
   "source": [
    "odds_admission2 = (93./243)\n",
    "print odds_admission2\n",
    "\n",
    "# The odds of being admitted to grad school when they didn't attend a #1 ranked college are ~0.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07949308756\n"
     ]
    }
   ],
   "source": [
    "# odds ratio = how much more likely are you to get admitted to grad school when attending a #1 ranked college\n",
    "# than if you didn't attend a #1 ranked college \n",
    "\n",
    "odds_ratio = odds_admission1 / odds_admission2\n",
    "print odds_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Here, you are roughly 3 times more likely to be admitted to grad school if you attended a #1 ranked college than if you attended a lower ranking school "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prestige_4.0    0   1\n",
      "admit                \n",
      "0             216  55\n",
      "1             114  12\n"
     ]
    }
   ],
   "source": [
    "print pd.crosstab(handCalc['admit'], handCalc['prestige_4.0'], rownames= ['admit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413397129187\n"
     ]
    }
   ],
   "source": [
    "odds_admittance3 = (12./55)\n",
    "\n",
    "odds_admittance4 = (114./216)\n",
    "\n",
    "odds_ratio2 = odds_admittance3 / odds_admittance4\n",
    "\n",
    "print odds_ratio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Based on this odds_ratio, applicants are 40% less likely to be admitted if they attended a school besides a #1 ranked institution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to train and predict on specific parts of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0      0  380.0  3.61             0             1             0\n",
       "1      1  660.0  3.67             0             1             0\n",
       "2      1  800.0  4.00             0             0             0\n",
       "3      1  640.0  3.19             0             0             1\n",
       "4      0  520.0  2.93             0             0             1\n",
       "5      1  760.0  3.00             1             0             0\n",
       "6      1  560.0  2.98             0             0             0\n",
       "7      0  400.0  3.08             1             0             0\n",
       "8      1  540.0  3.39             0             1             0\n",
       "9      0  700.0  3.92             1             0             0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317380</td>\n",
       "      <td>587.858942</td>\n",
       "      <td>3.392242</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.304786</td>\n",
       "      <td>0.168766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466044</td>\n",
       "      <td>115.717787</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.484159</td>\n",
       "      <td>0.460898</td>\n",
       "      <td>0.375017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa  prestige_2.0  prestige_3.0  \\\n",
       "count  397.000000  397.000000  397.000000    397.000000    397.000000   \n",
       "mean     0.317380  587.858942    3.392242      0.372796      0.304786   \n",
       "std      0.466044  115.717787    0.380208      0.484159      0.460898   \n",
       "min      0.000000  220.000000    2.260000      0.000000      0.000000   \n",
       "25%      0.000000  520.000000    3.130000      0.000000      0.000000   \n",
       "50%      0.000000  580.000000    3.400000      0.000000      0.000000   \n",
       "75%      1.000000  660.000000    3.670000      1.000000      1.000000   \n",
       "max      1.000000  800.000000    4.000000      1.000000      1.000000   \n",
       "\n",
       "       prestige_4.0  \n",
       "count    397.000000  \n",
       "mean       0.168766  \n",
       "std        0.375017  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'd like to see some summary statistics of the dataframe, so I can understand the data better\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFyCAYAAACk1ONFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYx0IwzAMwzAS8/8BNZIryiG8KU0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115e4fe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, as part of my exploratory analysis, I'm going to plot each column in the data frame \n",
    "# Why: to visualize the distribution of the data\n",
    "\n",
    "\n",
    "df.hist()\n",
    "plt.show()\n",
    "\n",
    "# Findings: \n",
    "# The most common GPA of the applicants was roughly 3.4\n",
    "# The most common GRE of the applicant group was around 600\n",
    "# Most applicants went to an above average college but not top ranked schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually add the intercept\n",
    "#data['intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0      0  380.0  3.61             0             1             0\n",
       "1      1  660.0  3.67             0             1             0\n",
       "2      1  800.0  4.00             0             0             0\n",
       "3      1  640.0  3.19             0             0             1\n",
       "4      0  520.0  2.93             0             0             1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del data['intercept']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'gre', u'gpa', u'prestige_2.0', u'prestige_3.0', u'prestige_4.0'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# I'm creating this variable so I don't have to type out all the covariates--i.e. all the different columns\n",
    "# I'm leaving out prestige_1.0 because we are treating it as our baseline and excluding it from the fit\n",
    "# Including prestige_1.0 would cause unnecessary collinearity\n",
    "\n",
    "train_cols = data.columns[1:]\n",
    "\n",
    "print train_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# creating a variable called 'logit', so I don't have retype the same parameter\n",
    "\n",
    "logit = sm.Logit(data['admit'], data[train_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589121\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  397\n",
      "Model:                          Logit   Df Residuals:                      392\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Wed, 08 Feb 2017   Pseudo R-squ.:                 0.05722\n",
      "Time:                        17:37:26   Log-Likelihood:                -233.88\n",
      "converged:                       True   LL-Null:                       -248.08\n",
      "                                        LLR p-value:                 1.039e-05\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------\n",
      "gre              0.0014      0.001      1.308      0.191        -0.001     0.003\n",
      "gpa             -0.1323      0.195     -0.680      0.497        -0.514     0.249\n",
      "prestige_2.0    -0.9562      0.302     -3.171      0.002        -1.547    -0.365\n",
      "prestige_3.0    -1.5375      0.332     -4.627      0.000        -2.189    -0.886\n",
      "prestige_4.0    -1.8699      0.401     -4.658      0.000        -2.657    -1.083\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tried to  use sklearn to fit the model & carry out the K-folds process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i realized that I'd rather fit the model using sklearn instead\n",
    "# sklearn will let me carry out the k-folds/cross-validation function with minimal effort\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as lm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize model and perform fit\n",
    "model2 = lm()\n",
    "features = train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0  380.0  3.61             0             1             0\n",
       "1  660.0  3.67             0             1             0\n",
       "2  800.0  4.00             0             0             0\n",
       "3  640.0  3.19             0             0             1\n",
       "4  520.0  2.93             0             0             1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[features]\n",
    "y = data.admit\n",
    "\n",
    "model2.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a variable called kf with 5 folds...using KFold attribute from sklearn\n",
    "\n",
    "kf = cross_validation.KFold(len(data), n_folds=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.317380352645\n"
     ]
    }
   ],
   "source": [
    "# get model outputs\n",
    "#print lm.coef_\n",
    "#print lm.intercept_\n",
    "print data.admit.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7037037   0.73417722  0.70886076  0.67088608  0.69620253]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model2, data[train_cols], data.admit, cv=5)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['probability'] = model.predict_proba(data[features[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0       0  380.0  3.61             0             1             0\n",
       "1       1  660.0  3.67             0             1             0\n",
       "2       1  800.0  4.00             0             0             0\n",
       "3       1  640.0  3.19             0             0             1\n",
       "4       0  520.0  2.93             0             0             1\n",
       "5       1  760.0  3.00             1             0             0\n",
       "6       1  560.0  2.98             0             0             0\n",
       "7       0  400.0  3.08             1             0             0\n",
       "8       1  540.0  3.39             0             1             0\n",
       "9       0  700.0  3.92             1             0             0\n",
       "10      0  800.0  4.00             0             0             1\n",
       "11      0  440.0  3.22             0             0             0\n",
       "12      1  760.0  4.00             0             0             0\n",
       "13      0  700.0  3.08             1             0             0\n",
       "14      1  700.0  4.00             0             0             0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### questions here -- cross validation -- feel like it shouldn't be this complicated\n",
    "# producing k folds cross-validation\n",
    "\n",
    "#mse_values = []\n",
    "#scores = []\n",
    "#n = 0\n",
    "#y = data.admit\n",
    "\n",
    "#for train_index, test_index in kf: \n",
    "    #lm_1 = lm.fit(data.iloc[train_index], y.iloc[train_index])\n",
    "    #mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    #scores.append(lm.score(train_cols, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### printing the summary results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0         1\n",
      "gre          -0.000680  0.003414\n",
      "gpa          -0.513657  0.249045\n",
      "prestige_2.0 -1.547279 -0.365166\n",
      "prestige_3.0 -2.188769 -0.886230\n",
      "prestige_4.0 -2.656743 -1.083112\n"
     ]
    }
   ],
   "source": [
    "# interested in seeing how 'robust' the coefficients are for the model\n",
    "\n",
    "print result.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gre             1.001368\n",
      "gpa             0.876073\n",
      "prestige_2.0    0.384342\n",
      "prestige_3.0    0.214918\n",
      "prestige_4.0    0.154135\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# odds ratios\n",
    "\n",
    "print np.exp(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  2.5%     97.5%        OR\n",
      "gre           0.999320  1.003420  1.001368\n",
      "gpa           0.598303  1.282800  0.876073\n",
      "prestige_2.0  0.212826  0.694082  0.384342\n",
      "prestige_3.0  0.112055  0.412207  0.214918\n",
      "prestige_4.0  0.070176  0.338540  0.154135\n"
     ]
    }
   ],
   "source": [
    "# odds ratio and 95% CI\n",
    "\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "print np.exp(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of being admitted to grad school decrease by roughly 50 percent when the applicants school prestige is 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For every 1 unit increase in GPA for all students, their odds of being admitted increase by roughly 200%. In other words, if students increase their GPA by any degree, their odds of being admitted will increase significantly more than any of the other covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recreate the dummy variables\n",
    "# because we did enumerate, we now need to reproduce the dummy variables to match the size of the data set. \n",
    "\n",
    "combos.columns = ['gre', 'gpa', 'prestige', 'intercept']\n",
    "dummy_ranks = pd.get_dummies(combos['prestige'], prefix='prestige')\n",
    "dummy_ranks.columns = ['prestige_1', 'prestige_2', 'prestige_3', 'prestige_4']\n",
    "\n",
    "\n",
    "# keep only what we need for making predictions\n",
    "cols_to_keep2 = ['gre', 'gpa']\n",
    "combos = combos[cols_to_keep2].join(dummy_ranks.ix[:, 'prestige_2':])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'admit', u'gre', u'gpa', u'prestige_2.0', u'prestige_3.0',\n",
       "       u'prestige_4.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combos.columns = [\"gre\",\"gpa\",\"prestige_2.0\",\"prestige_3.0\",\"prestige_4.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0  220.0  2.260000             0             0             0\n",
       "1  220.0  2.260000             1             0             0\n",
       "2  220.0  2.260000             0             1             0\n",
       "3  220.0  2.260000             0             0             1\n",
       "4  220.0  2.453333             0             0             0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### keep getting below error here--not sure why??\n",
    "# predict returns a series\n",
    "# predict_proba doesn't return a series\n",
    "\n",
    "# here, I'm adding a new column called 'admit_pred' -- which is prediction of whether or not someone will be admitted\n",
    "# based on the features provided\n",
    "combos['admit_pred'] = model2.predict(combos[[\"gre\",\"gpa\",\"prestige_2.0\",\"prestige_3.0\",\"prestige_4.0\"]])\n",
    "\n",
    "\n",
    "# here, I'm adding a new column called 'probability_1' -- which  is the probability of the someone being admitted\n",
    "combos['probability_1'] = model2.predict_proba(combos[[\"gre\",\"gpa\",\"prestige_2.0\",\"prestige_3.0\",\"prestige_4.0\"]]).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combos.drop([\"probability_0\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# by default, .predict produces a threshold of 50%, but for problems like cancer for instance\n",
    "# it's probably a bad idea to set thresholds at 50% because you'll end up getting a lot of false positives.\n",
    "# i.e. predicting that people have cancer when they actually don't\n",
    "\n",
    "# adding a new column to display the predicted outcome based on the new threshold of 'admit' vs. 'not admitted'\n",
    "# if I wanted to set thresholds for more than a binary outcome, I'd need to use multi class classification\n",
    "combos[\"new_threshold\"] = combos.probability_1.apply(lambda x: 0 if x < 0.20 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>admit_pred</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>new_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.289187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220.0</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre       gpa  prestige_2.0  prestige_3.0  prestige_4.0  admit_pred  \\\n",
       "0  220.0  2.260000             0             0             0           0   \n",
       "1  220.0  2.260000             1             0             0           0   \n",
       "2  220.0  2.260000             0             1             0           0   \n",
       "3  220.0  2.260000             0             0             1           0   \n",
       "4  220.0  2.453333             0             0             0           0   \n",
       "\n",
       "   probability_1  new_threshold  \n",
       "0       0.289187              1  \n",
       "1       0.182006              0  \n",
       "2       0.111899              0  \n",
       "3       0.093077              0  \n",
       "4       0.298505              1  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "-- above, the admit_pred column is predicting that the student in 'Row 1' for instance will not be admitted because they had a low GPA, low GRE, and attended a third tier school. \n",
    "\n",
    "-- the probability_1 column is providing us with the actual probability of the predicted outcome. For example, even though both the students from 'Row 3' & 'Row 4' were predicted to be rejected from grad school, the student from 'Row 4' will have a much greater chance of being admitted than the student in 'Row 3'\n",
    "\n",
    "-- the new_threshold column proves that the student in 'Row 4' had a much greater chance of acceptance that the student in 'Row 3'. It's easy to see, that if we change our threshold for being admitted from 50% probability to 20% probability, our predictions change for students in 'Row 0' and 'Row 4'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x118b86cd0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFdCAYAAABSLlSmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nePv/AZqncHtmFpuNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b86c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(combos.probability_1,combos.gre)\n",
    "plt.scatter(combos.probability_1,combos.gpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
